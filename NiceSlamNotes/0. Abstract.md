**Paper to understand:**
NICE-SLAM: Neural Implicit Scalable Encoding for SLAM
https://arxiv.org/abs/2112.12130

Project Repository
https://github.com/cvg/nice-slam

**Thinking about the goal:**
I explain the paper, its goal, terms, math and concepts in simple language to different target groups:
Child.
A reasonable person who does not know about computer stuff.
Applied Computer Science Student, like me.

Recall this every time i dig into the paper.

i) At the end i understand the paper.
ii) I can formulate the expos√© for the thesis.


---

To consider while reading the paper.
- Explainability to different target groups
- Write everything step down
- Note thoughts as well

---

### Understanding the "Title" of the paper

**Title:** NICE-SLAM: Neural Implicit Scalable Encoding for SLAM

**Observation:** The terms from the title are not known enough to grasp what is going on here.

Terms(child, student): @todo explain
`NICE-SLAM`

`Neural`
2025-04-04 13:09 
The fundamental concept the solution is build upon.
The solution must have something to do with some sort of training.

`Implicit`
`Scaleable`

`Encoding`
2025-04-04 13:17
Wie etwas gespeichert wird? Aber was, das trainierte Modell?
Der Algorithmus der durch das lernen 'encoded' sich ergibt?
Was Wie Wo

**Assumption:** The information must be in the paper.

**Steps:** 
i) Written down what i think some terms could mean, annotated with a date to observe later how my understanding changes.
ii) Continue to "Abstract" of the Paper.


### Understanding the "Abstract" section of the paper



|                                                                                                                                                  | Abstract                                                                                                                                                                  |
| ------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| @term Neural implicit representations?<br><br>@examples results in various domains?<br><br>@term simultaneous localization and mapping<br>(SLAM) | Neural implicit representations have recently shown encouraging results in various domains, including promising progress in simultaneous localization and mapping (SLAM). |
| @example oversmoothed scene reconstructions<br>@why difficulty scaling<br>up to large scenes                                                     | Nevertheless, existing methods produce oversmoothed scene reconstructions and have difficulty scaling<br>up to large scenes.                                              |
| simple fully-connected network architecture<br><br>local information in the observations<br>                                                     | These limitations are mainly due to their simple fully-connected network architecture that does not<br>incorporate local information in the observations.                 |


In this paper, we present NICE-SLAM, a ==dense SLAM system== that incorporates ==multi-level local information== by introducing
a ==hierarchical scene representation==. 

Optimizing this ==representation== with ==pre-trained geometric priors== enables detailed ==reconstruction== on large ==indoor scenes.== 

Compared to ==recent neural implicit SLAM systems==, our approach is more ==scalable, efficient, and robust==. 

Experiments on five ==challenging datasets== demonstrate competitive results of NICE-SLAM in both ==mapping== and ==tracking== quality. 


Observation:
Missing namings for 'other' systems and domains
lots of terms and concepts to review.
assumptions to be questioned

Assumption:
Some of this might be resolved while reading further.
I expect comparisons to the 'bad' solutions to be in this paper.

Step:
Procede to the next section "1. Introduction"

